name: MaxVQA
split_seed: 42

wandb:
    project_name: MaxVQA

data: 
    train-maxwell:
        type: ViewDecompositionDataset
        args:
            weight: 0.598
            phase: test
            anno_file: ./examplar_data_labels/MaxWell/train_labels.txt
            data_prefix: ../datasets/MaxWell/videos
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 4
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 64
                    frame_interval: 2
                    t_frag: 64
                    num_clips: 1
                    
    val-cvd2014:
        type: ViewDecompositionDataset
        args:
            weight: 0.598
            phase: test
            anno_file: ./examplar_data_labels/CVD2014/labels.txt
            data_prefix: ../datasets/CVD2014/
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 4
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 64
                    frame_interval: 2
                    t_frag: 64
                    num_clips: 1                    
                    
    val-livevqc:
        type: ViewDecompositionDataset
        args:
            weight: 0.598
            phase: test
            anno_file: ./examplar_data_labels/LIVE_VQC/labels.txt
            data_prefix: ../datasets/LIVE_VQC/
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 4
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 64
                    frame_interval: 2
                    t_frag: 64
                    num_clips: 1
    val-maxwell:
        type: ViewDecompositionDataset
        args:
            weight: 0.598
            phase: test
            anno_file: ./examplar_data_labels/MaxWell/test_labels.txt
            data_prefix: ../datasets/MaxWell/videos
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 4
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 64
                    frame_interval: 2
                    t_frag: 64
                    num_clips: 1
                    
    val-kv1k:
        type: ViewDecompositionDataset
        args:
            weight: 0.540
            phase: test
            anno_file: ./examplar_data_labels/KoNViD/labels.txt
            data_prefix: ../datasets/KoNViD/
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 4
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 64
                    frame_interval: 2
                    t_frag: 64
                    num_clips: 1
                    
    val-ytugc:
        type: ViewDecompositionDataset
        args:
            weight: 0.443
            phase: test
            anno_file: ./examplar_data_labels/YouTubeUGC/labels.txt
            data_prefix: ../datasets/YouTubeUGC/
            sample_types:
                technical:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 4
                    upsample: 1080
                aesthetic:
                    size_h: 224
                    size_w: 224
                    clip_len: 64
                    frame_interval: 2
                    t_frag: 64
                    num_clips: 1
                    
                    
model:
    type: DOVER
    args:
        backbone:
            technical:
                type: swin_tiny_grpb
                checkpoint: true
                pretrained:
        backbone_preserve_keys: technical
        divide_head: true
        vqa_head:
            in_channels: 768
            hidden_channels: 64
                    






    
        
